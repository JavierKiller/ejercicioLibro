---
title: "Proportions: testing and power"
---

## Life after death

In this chapter, you'll continue to dig into the data from the General Social Survey. One of the questions that was asked of respondents was: "Do you believe there is a life after death?"

Let's see how your sample of Americans responded to this question in 2016.

## Instructions `100 XP` {.unnumbered}

- Using gss2016, visualize the distribution of postlife as a bar plot.

- Compute the proportion of respondents that do believe in life after death and save it has p_hat.

``` {.r filename="E1.R"}
# Using `gss2016`, plot postlife
ggplot(gss2016, aes(x = postlife)) +
  # Add bar layer
  geom_bar()



# From previous step
ggplot(gss2016, aes(x = postlife)) +
  geom_bar()

# Compute and save proportion that believe
p_hat <- gss2016 %>%
  summarize(prop_yes = mean(postlife == "YES")) %>%
  pull()

# See the result
p_hat
```

## Generating from H0

Imagine that when reading the newspaper, you come across someone who makes the following claim: "3/4 of all Americans believe in life after death". This can be interpreted as a point null hypothesis that the population proportion has a value of 0.75.

Use this hypothesis to generate a single dataset to explore.

## Instructions `100 XP` {.unnumbered}

- Using gss2016,
 - Specify the variable of interest and what constitutes a success.
 - Form a "point" null hypothesis that the true proportion is 0.75.
 - Generate a single simulated dataset under this null hypothesis. 

- Using sim1, construct a bar plot to visualize the distribution of postlife.

- Compute the proportion of simulated respondents in sim1 that believe in life after death.
``` {.r filename="E2.R"}
# Generate one dataset under H0
sim1 <- gss2016 %>%
  # Specify the response and success
  specify(response = postlife, success = "YES") %>%
  # Hypothesize the null value of p
  hypothesize(null = "point", p = 0.75) %>%
  # Generate a single simulated dataset
  generate(reps = 1, type = "simulate")

# See the result
sim1




# From previous step
sim1 <- gss2016 %>%
  specify(response = postlife, success = "YES") %>%
  hypothesize(null = "point", p = 0.75) %>%
  generate(reps = 1, type = "simulate")

# Using sim1, plot postlife
ggplot(sim1, aes(x = postlife)) +
  # Add bar layer
  geom_bar()




# From previous steps
sim1 <- gss2016 %>%
  specify(response = postlife, success = "YES") %>%
  hypothesize(null = "point", p = 0.75) %>%
  generate(reps = 1, type = "simulate")

# Compute proportion that believe
sim1 %>%
  summarize(prop_yes = mean(postlife == "YES")) %>%
  pull()
```

## Testing a claim

In the last exercise, you got a sense of what a single simulated p-hat might be if in fact the true proportion of believers was 0.75. That p-hat was likely different from the p-hat in gss2016, but was that a fluke or is there a systematic inconsistency between that claim and the data in the GSS?

In this exercise, you'll settle this question.

## Instructions `100 XP` {.unnumbered}

- Extend your code for the last exercise to calculate() sample proportions of believers in 500 generated datasets. Save this collection of p-hats to null.

- Visualize the null distribution by creating a density plot of the statistics. Using geom_vline(), add a vertical line at the value of p_hat (from the last exercise), colored "red".

- Compute the one-tailed p-value by finding the proportion of null values that are greater than or equal to your observed p_hat.
- Compute the two-tailed p-value (where the proportion of null values is equal to or more extreme than the observed p_hat) from this by multiplying by 2.
``` {.r filename="E3.R"}
# Generate null distribution
null <- gss2016 %>%
  specify(response = postlife, success = "YES") %>%
  hypothesize(null = "point", p = 0.75) %>%
  generate(reps = 500, type = "simulate") %>%
  # Calculate proportions
  calculate(stat = "prop")





# From previous step
null <- gss2016 %>%
  specify(response = postlife, success = "YES") %>%
  hypothesize(null = "point", p = 0.75) %>%
  generate(reps = 500, type = "simulate") %>%
  calculate(stat = "prop")
  
# Visualize null distribution
ggplot(null, aes(x = stat)) +
  # Add density layer
  geom_density() +
  # Add line at observed
  geom_vline(xintercept = p_hat, color = "red")  




# From previous step
null <- gss2016 %>%
  specify(response = postlife, success = "YES") %>%
  hypothesize(null = "point", p = 0.75) %>%
  generate(reps = 500, type = "simulate") %>%
  calculate(stat = "prop")
  
null %>%
  summarize(
    # Compute the one-tailed p-value
    one_tailed_pval = mean(stat >= p_hat),
    # Compute the two-tailed p-value
    two_tailed_pval = 2 * one_tailed_pval
  ) %>%
  pull(two_tailed_pval)
```

## Death penalty and sex

While you're on the topic of death and the afterlife, take a look at another question from the GSS:

Do you favor or oppose the death penalty for people convicted of murder?

Your objective here is to explore if opinions on capital punishment (cappun) diverged between men and women in the gss2016 data.

## Instructions `100 XP` {.unnumbered}

- Construct a bar plot to visualize the distribution of cappun broken down by sex. To enable easy comparison, be sure you're plotting proportions instead of counts (recall this means you set the position of the bars so that they "fill" the plot).

-Compute the proportion that FAVOR for men and women respectively, then save that two-element vector to p_hats. pull() is used (here and elsewhere) to pull the values out of the data frame for subsequent computation.

- Compute the difference in p_hats using the diff() function and save it to d_hat.
``` {.r filename="E4.R"}
# Plot distribution of sex filled by cappun
ggplot(gss2016, aes(x = sex, fill = cappun)) +
  # Add bar layer
  geom_bar(position = "fill")




# Compute two proportions
p_hats <- gss2016 %>%
  # Group by sex
  group_by(sex) %>%
  # Calculate proportion that FAVOR
  summarize(prop_favor = mean(cappun == "FAVOR")) %>%
  pull()

# See the result
p_hats




# From previous step
p_hats <- gss2016 %>%
  group_by(sex) %>%
  summarize(prop_favor = mean(cappun == "FAVOR")) %>%
  pull()
  
# Compute difference in proportions
d_hat <- diff(p_hats)

# See the result
d_hat
```

## Hypothesis test on the difference in proportions

In the last exercise you learned that about 52% of women favor the death penalty while about 63% of men do, a difference of about 11 percentage points. That seems like a large difference, but what if it's just due to chance and in fact there is no relationship between sex and support for the death penalty? Find out by testing the null hypothesis that sex and support for the death penalty are independent of one another.

The statistic that you'll be using in this exercise is a "diff in props", which requires that you specify the order of the difference by adding an argument, order = c("FIRST", "SECOND"), where first and second refer to the group names. This results in the calculation: FIRST - SECOND.

## Instructions `100 XP` {.unnumbered}

- Set up an infer chain which ends with the calculation of many differences in proportions, calculated as the proportion of "FEMALE" that "FAVOR" minus the proportion of "MALE" that do. Save the result to null.

- Construct a density plot to visualize the statistics stored in the null distribution and add a vertical red line to indicate the observed test statistic d_hat that you calculated in the last exercise.

- Compute the two-tailed p-value.
 - Compute the one-tailed p-value by summarizing the statistics column by the proportion of statistics that are less than or equal to d_hat.
 - Double it to get the two-tailed p-value.
``` {.r filename="E5.R"}
# Create null distribution
null <- gss2016 %>%
  # specify the response and explanatory as well as the success
  specify(cappun ~ sex, success = "FAVOR") %>%
  # set up null hypothesis
  hypothesize(null = "independence") %>%
  # generate 500 permuted reps
  generate(reps = 500, type = "permute") %>%
  # calculate the statistics
  calculate(stat = "diff in props", order = c("FEMALE", "MALE"))



# From previous step
null <- gss2016 %>%
  specify(cappun ~ sex, success = "FAVOR") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 500, type = "permute") %>%
  calculate(stat = "diff in props", order = c("FEMALE", "MALE"))
  
# Visualize null
ggplot(null, aes(x = stat)) +
  # Add density layer
  geom_density() +
  # Add red vertical line at obs stat
  geom_vline(xintercept = d_hat, color = "red")



# From previous step
null <- gss2016 %>%
  specify(cappun ~ sex, success = "FAVOR") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 500, type = "permute") %>%
  calculate(stat = "diff in props", order = c("FEMALE", "MALE"))
  
# Compute two-tailed p-value
null %>%
  summarize(
    one_tailed_pval = mean(stat <= d_hat),
    two_tailed_pval = 2 * one_tailed_pval
  ) %>%
  pull(two_tailed_pval)
```

## Hypothesis tests and confidence intervals

As was mentioned at the very beginning of this chapter, there is a close link between hypothesis tests and confidence intervals. The former explores whether a particular hypothesis about the world is consistent with your data. The latter has no hypothesis, it simply quantifies your uncertainty in your point estimate by adding and subtracting the margin of error.

In this exercise you will explore the duality by forming a confidence interval around the difference in proportions, d_hat. To get you started, here is the code that you used to form the null distribution:

> # Reference code for null distribution
> null <- gss2016 %>%
>    specify(cappun ~ sex, success = "FAVOR") %>%
>    hypothesize(null = "independence") %>%
>    generate(reps = 500, type = "permute") %>%
>    calculate(stat = "diff in props", order = c("FEMALE", "MALE"))`

## Instructions `100 XP` {.unnumbered}

- Adapt the code used to form the null distribution for hypothesis test to form the bootstrap distribution for use in a confidence interval.
 - Remove the hypothesis step.
 - Change the generation type to "bootstrap".
 - Save it as boot.

- Compute the standard deviation, sd(), of the bootstrap distribution to estimate the standard error and save it as SE.
- Formulate the 95% confidence interval for d_hat by subtracting and adding 2 SEs.
``` {.r filename="E6.R"}
# Create the bootstrap distribution
boot <- gss2016 %>%
  # Specify the variables and success
  specify(cappun ~ sex, success = "FAVOR") %>%
  # Generate 500 bootstrap reps
  generate(reps = 500, type = "bootstrap") %>%
  # Calculate the statistics
  calculate(stat = "diff in props", order = c("FEMALE", "MALE"))




# From previous step
boot <- gss2016 %>%
  specify(cappun ~ sex, success = "FAVOR") %>%
  generate(reps = 500, type = "bootstrap") %>%
  calculate(stat = "diff in props", order = c("FEMALE", "MALE"))
    
# Compute the standard error
SE <- boot %>%
  summarize(se = sd(stat)) %>%
  pull()
  
# Form the CI (lower, upper)
c(d_hat - 2 * SE, d_hat + 2 * SE)
```

## When the null is true: decision

In the last exercise, the observed difference in proportions is comfortably in the middle of the null distribution. In this exercise, you'll come to a formal decision on if you should reject the null hypothesis, but instead of using p-values, you'll use the notion of a rejection region.

The rejection region is the range of values of the statistic that would lead you to reject the null hypothesis. In a two-tailed test, there are two rejection regions. You know that the upper region should contain the largest 2.5% of the null statistics (when alpha = .05), so you can extract the cutoff value by finding the .975 quantile(). Similarly, the lower region contains the smallest 2.5% of the null statistics, which can also be found using quantile().

Here's a quick look at how the quantile() function works for this simple dataset x.

x <- c(0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20)
quantile(x, probs = .5)
quantile(x, probs = .8)
Once you have the rejection region defined by the upper and lower cutoffs, you can make your decision regarding the null by checking if your observed statistic falls between those cutoffs (in which case you will fail to reject) or outside of them (in which case you will reject).

## Instructions `100 XP` {.unnumbered}

- Create an object called alpha that takes the value 0.05.
- Find the upper cutoff by starting with the null data frame, which has been carried over from the last exercise, and summarizing the stat column by finding the alpha / 2 quantile(). Save this value as lower. Next, find the 1 - alpha / 2 quantile() and save it to upper.
- Check if your observed value of d_hat is between() the lower and upper cutoffs to find whether you should fail to reject the null hypothesis.

- Visualize the reject and fail to reject regions by starting with your null distribution from last time and adding one vertical blue line for each cutoff.
``` {.r filename="E7.R"}
# Set alpha
alpha <- 0.05

# Find cutoffs
lower <- null %>%
  summarize(l = quantile(stat, probs = alpha / 2)) %>%
  pull()
upper <- null %>%
  summarize(u = quantile(stat, probs = 1 - alpha / 2)) %>%
  pull()
  
# Is d_hat inside cutoffs?
d_hat %>%
  between(lower, upper)



# From previous step
alpha <- 0.05
upper <- null %>%
  summarize(u = quantile(stat, probs = 1 - alpha / 2)) %>%
  pull()
lower <- null %>%
  summarize(l = quantile(stat, probs = alpha / 2)) %>%
  pull()
  
# Visualize cutoffs
ggplot(null, aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = d_hat, color = "red") +
  # Add vertical blue line for lower cutoff
  geom_vline(xintercept = lower, color = "blue") +
  # Add vertical blue line for upper cutoff
  geom_vline(xintercept = upper, color = "blue")
```